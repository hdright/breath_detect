{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "批训练：把数据分为一小批一小批进行训练\n",
    "Dataloader就是用来包装使用的数据，\n",
    "比如说该程序中把数据5个5个的打包，\n",
    "每一次抛出一组数据进行操作。\n",
    "'''\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "torch.manual_seed(1)\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "df = pd.DataFrame(data=preprocessing.StandardScaler().fit_transform(np.random.randint(0, 10, size=(20, 10))))\n",
    "#    y = pd.Series(np.random.randint(0, 2, 200))\n",
    "def get_tensor_from_pd(dataframe_series) -> torch.Tensor:\n",
    "    return torch.tensor(data=dataframe_series.values)\n",
    "x = get_tensor_from_pd(df).float()#, get_tensor_from_pd(y).float()\n",
    "# x = np.random.randint(0, 10, size=(200, 5))\n",
    "y = torch.linspace(11,21,20)\n",
    " \n",
    "torch_dataset = Data.TensorDataset(x,y) #把数据放在数据库中\n",
    "loader = Data.DataLoader(\n",
    "    # 从dataset数据库中每次抽出batch_size个数据\n",
    "    dataset=torch_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,#将数据打乱\n",
    "    num_workers=2, #使用两个线程\n",
    ")\n",
    "def show_batch():\n",
    "    for epoch in range(3): #对全部数据进行3次训练\n",
    "        for step,(batch_x,batch_y) in enumerate(loader): # 每一次挑选出来的size个数据\n",
    " \n",
    "            # training\n",
    " \n",
    "            # 打印出来，观察数据\n",
    "            print('Epoch:',epoch,'|Step:',step,'|batch x:',\n",
    "                  batch_x.numpy(),'|batch y:',batch_y.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading file TestCfgData001.txt ...\n",
      "\n",
      "Now reading file TestCfgData002.txt ...\n",
      "\n",
      "Now reading file TestCfgData003.txt ...\n",
      "\n",
      "Now reading file TestCfgData004.txt ...\n",
      "\n",
      "Now reading file TestCfgData005.txt ...\n",
      "\n",
      "Now reading file TestCfgData006.txt ...\n",
      "\n",
      "Now reading file TestCfgData007.txt ...\n",
      "\n",
      "Now reading file TestCfgData008.txt ...\n",
      "\n",
      "Now reading file TestCfgData009.txt ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from chusai import *\n",
    "from scipy.io import savemat\n",
    "PathSet = {0:\"./TestData\", 1:\"./CompetitionData1\", 2:\"./CompetitionData2\", 3:\"./CompetitionData3\", 4:\"./CompetitionData4\"}\n",
    "PrefixSet = {0:\"Test\" , 1:\"Round1\", 2:\"Round2\", 3:\"Round3\", 4:\"Round4\"}\n",
    "\n",
    "Ridx = 0 # 设置比赛轮次索引，指明数据存放目录。0:Test; 1: 1st round; 2: 2nd round ...\n",
    "PathRaw = \"./chusai_data/\" + PathSet[Ridx]\n",
    "PathOut = \"./outputs/\" + PathSet[Ridx]\n",
    "PathTrain = './train_data/' \n",
    "Prefix = PrefixSet[Ridx]\n",
    "\n",
    "## 1查找文件\n",
    "names= FindFiles(PathRaw) # 查找文件夹中包含的所有比赛/测试数据文件，非本轮次数据请不要放在目标文件夹中\n",
    "\n",
    "dirs = os.listdir(PathRaw)\n",
    "names = []  # 文件编号\n",
    "files = []\n",
    "for f in sorted(dirs):\n",
    "    if f.endswith('.txt'):\n",
    "        files.append(f)\n",
    "for f in sorted(files):\n",
    "    if f.find('CfgData')!=-1 and f.endswith('.txt'):\n",
    "        names.append(f.split('CfgData')[-1].split('.txt')[0])\n",
    "\n",
    "## 2创建对象并处理\n",
    "Rst = []\n",
    "Gt  = []\n",
    "# for na in names: #\n",
    "for na in [names[0]]:#\n",
    "    # 读取配置及CSI数据\n",
    "    Cfg = CfgFormat(PathRaw + '/' + Prefix + 'CfgData' + na + '.txt')\n",
    "    csi = np.genfromtxt(PathRaw + '/' + Prefix + 'InputData' + na + '.txt', dtype = float)\n",
    "    CSI = csi[:,0::2] + 1j* csi[:,1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nsamp': 68,\n",
       " 'Np': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1]),\n",
       " 'Ntx': 1,\n",
       " 'Nrx': 3,\n",
       " 'Nsc': 30,\n",
       " 'Nt': array([1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500,\n",
       "        1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501,\n",
       "        1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501, 1501, 6000,\n",
       "        6000, 6000, 6000, 6000, 4800, 4800, 1500, 1500, 4800, 4800, 4800,\n",
       "        4800, 4800, 4800, 4800, 1500, 1500, 1500, 1500, 1500, 1500, 1500,\n",
       "        1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500, 1500,\n",
       "        1500, 1500]),\n",
       " 'Tdur': array([30.059486, 30.299162, 30.299324, 30.099274, 30.059309, 30.099408,\n",
       "        30.399524, 30.059742, 30.03952 , 30.059552, 29.99948 , 30.159336,\n",
       "        30.219226, 30.339485, 30.479488, 30.259349, 30.879334, 30.499545,\n",
       "        30.399494, 30.479374, 30.019402, 30.079377, 30.379308, 30.099398,\n",
       "        30.239535, 30.099296, 30.559242, 30.640422, 31.199195, 30.319457,\n",
       "        30.419277, 30.559245, 60.669012, 60.768749, 60.838882, 60.899537,\n",
       "        61.498587, 62.384279, 62.559944, 30.059397, 30.399284, 62.135123,\n",
       "        61.860054, 61.935247, 62.635009, 61.297754, 60.384843, 60.422504,\n",
       "        30.200754, 30.300738, 30.280695, 30.280786, 30.220782, 30.140776,\n",
       "        30.380782, 30.240835, 30.220786, 30.00105 , 30.120804, 30.200759,\n",
       "        30.90071 , 39.62106 , 33.600919, 35.161044, 33.438742, 34.721081,\n",
       "        41.598737, 47.082275]),\n",
       " 'fstart': 5300.0,\n",
       " 'fend': 5336.25}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154221, 90)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([22.440194]),\n",
       " array([22.428071]),\n",
       " array([21.130579]),\n",
       " array([20.390532]),\n",
       " array([20.399487]),\n",
       " array([20.586328]),\n",
       " array([18.350859]),\n",
       " array([21.685914]),\n",
       " array([19.647731]),\n",
       " array([20.759867]),\n",
       " array([19.461718]),\n",
       " array([16.309124]),\n",
       " array([17.981956]),\n",
       " array([19.650385]),\n",
       " array([20.190844]),\n",
       " array([20.013712]),\n",
       " array([19.466318]),\n",
       " array([20.387775]),\n",
       " array([20.204478]),\n",
       " array([19.825724]),\n",
       " array([20.020472]),\n",
       " array([18.896096]),\n",
       " array([24.639865]),\n",
       " array([19.65238]),\n",
       " array([17.416404]),\n",
       " array([19.457776]),\n",
       " array([19.456463]),\n",
       " array([19.83242]),\n",
       " array([16.497238]),\n",
       " array([25.572213]),\n",
       " array([20.388464]),\n",
       " array([17.422281]),\n",
       " array([14.939751]),\n",
       " array([19.569505]),\n",
       " array([36.626195]),\n",
       " array([18.91996]),\n",
       " array([22.809468]),\n",
       " array([10.649476, 23.225623]),\n",
       " array([ 8.147241, 21.925367]),\n",
       " array([11.120982, 15.02144 , 27.102235]),\n",
       " array([11.116103, 14.650046, 21.718914]),\n",
       " array([14.446246]),\n",
       " array([14.350254]),\n",
       " array([15.462023]),\n",
       " array([15.835575]),\n",
       " array([13.979689]),\n",
       " array([8.241491]),\n",
       " array([19.165179]),\n",
       " array([24.810998]),\n",
       " array([16.279269]),\n",
       " array([18.859813]),\n",
       " array([15.528021]),\n",
       " array([17.954141]),\n",
       " array([16.27325]),\n",
       " array([18.858441]),\n",
       " array([14.236744]),\n",
       " array([16.847891]),\n",
       " array([20.158361]),\n",
       " array([18.299257]),\n",
       " array([22.185333]),\n",
       " array([23.093671]),\n",
       " array([24.577313]),\n",
       " array([20.69615]),\n",
       " array([17.742286]),\n",
       " array([24.29914]),\n",
       " array([20.238601]),\n",
       " array([21.166017]),\n",
       " array([19.41299])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(PathRaw + '/' + Prefix + 'GroundTruthData' + na + '.txt', 'r') as f:\n",
    "    gt = [np.fromstring(arr.strip(), dtype=float, sep = ' ') for arr in f.readlines()]\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4680, 1500, 2)\n",
      "(4680, 1)\n"
     ]
    }
   ],
   "source": [
    "Nt = [0] + list(accumulate(Cfg['Nt']))\n",
    "# 记录Np=1、Nt<1600的CSI样本有多少个\n",
    "CSI_Np1_Nt1600_cnt = 0\n",
    "for ii in range(Cfg['Nsamp']):\n",
    "    # CSI_s.append(CsiFormatConvrt(CSI[Nt[ii]:Nt[ii+1],:], Cfg['Nrx'],\n",
    "    #                                     Cfg['Ntx'], Cfg['Nsc'], Cfg['Nt'][ii]))\n",
    "    if Cfg['Np'][ii] == 1 and Cfg['Nt'][ii] < 1600:\n",
    "        CSI_Np1_Nt1600_cnt += 1\n",
    "\n",
    "\n",
    "# 生成训练数据集\n",
    "CSI_train = np.zeros((CSI_Np1_Nt1600_cnt*CSI.shape[1], 1500), dtype = complex) # CSI序列\n",
    "GT_train = np.zeros((CSI_Np1_Nt1600_cnt*CSI.shape[1], 1), dtype = float) # 呼吸速率真实值\n",
    "CSI_Np1_Nt1600_cnt = 0\n",
    "for ii in range(Cfg['Nsamp']):\n",
    "    if Cfg['Np'][ii] == 1 and Cfg['Nt'][ii] < 1600:\n",
    "        CSI_Np1_Nt1600_cnt += 1\n",
    "        CSI_Nsamp = np.transpose(CSI[Nt[ii]:Nt[ii+1],:]) #90,1500\n",
    "        CSI_train[(CSI_Np1_Nt1600_cnt-1)*CSI.shape[1]:CSI_Np1_Nt1600_cnt*CSI.shape[1],:] = CSI_Nsamp[:,0:1500]\n",
    "        GT_train[(CSI_Np1_Nt1600_cnt-1)*CSI.shape[1]:CSI_Np1_Nt1600_cnt*CSI.shape[1],0] = gt[ii]\n",
    "\n",
    "# CSI序列实虚部分开,savgol_filter滤波，归一化,最后把实虚部分作为第三个维度合并\n",
    "CSI_train_real = savgol_filter(np.real(CSI_train), 8, 7, axis=1)\n",
    "CSI_train_imag = savgol_filter(np.imag(CSI_train), 8, 7, axis=1)\n",
    "CSI_train_real = preprocessing.StandardScaler().fit_transform(CSI_train_real)\n",
    "CSI_train_imag = preprocessing.StandardScaler().fit_transform(CSI_train_imag)\n",
    "CSI_train_conca = np.concatenate((CSI_train_real[:,:,np.newaxis], CSI_train_imag[:,:,np.newaxis]), axis=2)\n",
    "\n",
    "# for i in range(CSI_train_conca.shape[0]):\n",
    "#     print(np.min(CSI_train_conca[i,:]), np.max(CSI_train_conca[i,:]))\n",
    "print(CSI_train_conca.shape)\n",
    "print(GT_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 1500, 2)\n"
     ]
    }
   ],
   "source": [
    "# 保存前4500个样本作为训练集\n",
    "CSI_train_conca = CSI_train_conca[0:4500,:]\n",
    "GT_train = GT_train[0:4500,:]\n",
    "print(CSI_train_conca.shape)\n",
    "np.save(PathTrain + '/CSI_train_conca.npy', CSI_train_conca)\n",
    "np.save(PathTrain + '/GT_train.npy', GT_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bolt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
